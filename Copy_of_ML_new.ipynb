{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ML_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpVFN2/c+HRh4cPnXmjJkm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaoranYueRyan/Data-Science-analysis-Approaches/blob/master/Copy_of_ML_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZlmvw4hdDBE",
        "outputId": "8c82ed17-de57-42ba-8757-295d66c651c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aif360[LFR] in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "\u001b[33mWARNING: aif360 0.4.0 does not provide the extra 'lfr'\u001b[0m\n",
            "Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360[LFR]) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360[LFR]) (1.21.6)\n",
            "Requirement already satisfied: tempeh in /usr/local/lib/python3.7/dist-packages (from aif360[LFR]) (0.1.12)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360[LFR]) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360[LFR]) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360[LFR]) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360[LFR]) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360[LFR]) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360[LFR]) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360[LFR]) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360[LFR]) (3.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360[LFR]) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360[LFR]) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360[LFR]) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->aif360[LFR]) (4.2.0)\n",
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360[LFR]) (0.60.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360[LFR]) (2.23.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360[LFR]) (0.40.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360[LFR]) (3.6.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler->tempeh->aif360[LFR]) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360[LFR]) (57.4.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360[LFR]) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360[LFR]) (1.11.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360[LFR]) (8.12.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360[LFR]) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->tempeh->aif360[LFR]) (21.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360[LFR]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360[LFR]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360[LFR]) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360[LFR]) (2.10)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360[LFR]) (21.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360[LFR]) (0.51.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360[LFR]) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360[LFR]) (4.64.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360[LFR]) (0.0.7)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap->tempeh->aif360[LFR]) (0.34.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install 'aif360[LFR]'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yObjAqQedhIW",
        "outputId": "79920c80-daa5-4cfa-a646-9913a8febac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVpVYVnPdmBt",
        "outputId": "bb6027ab-5fe8-4673-ea39-940a74e5bdf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-26 17:35:33--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3974305 (3.8M) [application/x-httpd-php]\n",
            "Saving to: ‘adult.data.45’\n",
            "\n",
            "adult.data.45       100%[===================>]   3.79M  3.18MB/s    in 1.2s    \n",
            "\n",
            "2022-04-26 17:35:35 (3.18 MB/s) - ‘adult.data.45’ saved [3974305/3974305]\n",
            "\n",
            "--2022-04-26 17:35:35--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5229 (5.1K) [application/x-httpd-php]\n",
            "Saving to: ‘adult.names.45’\n",
            "\n",
            "adult.names.45      100%[===================>]   5.11K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-26 17:35:36 (73.3 MB/s) - ‘adult.names.45’ saved [5229/5229]\n",
            "\n",
            "--2022-04-26 17:35:36--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2003153 (1.9M) [application/x-httpd-php]\n",
            "Saving to: ‘adult.test.45’\n",
            "\n",
            "adult.test.45       100%[===================>]   1.91M  1.82MB/s    in 1.0s    \n",
            "\n",
            "2022-04-26 17:35:38 (1.82 MB/s) - ‘adult.test.45’ saved [2003153/2003153]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fairlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKu5vxQ8PKGV",
        "outputId": "2aba10e2-8899-4627-8ccc-5763497536af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fairlearn in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from fairlearn) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->fairlearn) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.1->fairlearn) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->fairlearn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
        "import fairlearn.reductions as red\n",
        "\n",
        "privileged_groups=[{'sex':1}]\n",
        "unprivileged_groups = [{'sex': 0}]\n",
        "dataset_orig = load_preproc_data_adult(['sex'])\n",
        "\n",
        "\n",
        "#STEP 3: We split between training and test set.\n",
        "train_all, test_all = dataset_orig.split([0.7], shuffle=True)\n",
        "print(\"training data size\", train_all.features.shape)\n",
        "print(\"dataset feature names\", train_all.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6FU9OM9dmEG",
        "outputId": "13ebe429-10f0-4a11-d2a5-c87d065c1019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data size (34189, 18)\n",
            "dataset feature names ['race', 'sex', 'Age (decade)=10', 'Age (decade)=20', 'Age (decade)=30', 'Age (decade)=40', 'Age (decade)=50', 'Age (decade)=60', 'Age (decade)=>=70', 'Education Years=6', 'Education Years=7', 'Education Years=8', 'Education Years=9', 'Education Years=10', 'Education Years=11', 'Education Years=12', 'Education Years=<6', 'Education Years=>12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "\n",
        "\n",
        "#Normalize the dataset, both train and test. This should always be done in any machine learning pipeline!\n",
        "scale_orig = StandardScaler()\n",
        "X_train = scale_orig.fit_transform(train_all.features)\n",
        "y_train = train_all.labels.ravel()\n",
        "\n",
        "X_test = scale_orig.transform(test_all.features) \n",
        "y_test = test_all.labels.ravel()"
      ],
      "metadata": {
        "id": "tS2fXXIqdmGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf=KFold(n_splits=5,shuffle=True)\n",
        "kf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBkI0eJPdmId",
        "outputId": "c9231a9a-3075-4f20-8bf2-a621cd7ff162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KFold(n_splits=5, random_state=None, shuffle=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(model,X_train,X_test,y_train,y_test):\n",
        "  model.fit(X_train,y_train)\n",
        "  return model.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "BAMpo7JwdmKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojHmgHCcdmOV",
        "outputId": "f82812ed-4924-4290-8ade-2157ea45cc82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8261.0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import copy \n",
        "def new_metrix(dataset,y_prediction,unprivileged_groups, privileged_groups,index):\n",
        "  dataset_pred=copy.deepcopy(dataset)\n",
        "  y_prediction.resize((len(y_prediction),1))\n",
        "  dataset_pred.labels[index]=y_prediction\n",
        "  \n",
        "  metric = ClassificationMetric(dataset, dataset_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "  metric_arrs = {}\n",
        "  metric_arrs['stat_par_diff']=(metric.statistical_parity_difference())\n",
        "  metric_arrs['eq_opp_diff']=(metric.equal_opportunity_difference())\n",
        "  metric_arrs['avg_odds_diff']=(metric.average_odds_difference())\n",
        "  # df=pd.DataFrame(metric_arrs,index[0,1,2])\n",
        "  return metric_arrs\n",
        "  # stat_par_diff.append(metric.statistical_parity_difference())\n",
        "  # print(stat_par_diff)\n",
        "  #     # metric_arrs['eq_opp_diff']=(metric.equal_opportunity_difference())\n",
        "  #     # eq_opp_diff.append(metric.equal_opportunity_difference())\n",
        "  #     # print(eq_opp_diff)\n",
        "  # metric_arrs['avg_odds_diff']=(metric.average_odds_difference())\n",
        "  # avg_odds_diff.append(metric.average_odds_difference())\n",
        "  #   # metric_arrs['mean_stat_par_diff'].append(mean(stat_par_diff))\n",
        "  #   # print(mean(stat_par_diff))\n",
        "  #   # metric_arrs['eq_opp_diff'].append(mean(eq_opp_diff))\n",
        "  #   # metric_arrs['avg_odds_diff'].append(mean(avg_odds_diff))\n",
        "  #   # metric_arrs['C_slover'].append(C_arr+'_'+slov)\n"
      ],
      "metadata": {
        "id": "UMcrDXmCjWEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.metrics import ClassificationMetric\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "# data=train.copy()\n",
        "score_mean=[]\n",
        "stat_par_diff=[]\n",
        "eq_opp_diff=[]\n",
        "avg_odds_diff=[]\n",
        "C_array_1=[1.0, 0.001, 0.000001]\n",
        "C_array=[1.0, 0.001]\n",
        "solver_array=['saga']\n",
        "solver_array_1=['saga']\n",
        "\n",
        "kernel_1=['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
        "kernel=['linear']\n",
        "for ker in kernel:\n",
        "  for C_arr in C_array:\n",
        "    learner = SVC(gamma='auto',kernel=ker,C=C_arr)\n",
        "\n",
        "    for train_index,test_index in kf.split(X_train):\n",
        "      print('all')\n",
        "      train_x,test_x,train_y,test_y=X_train[train_index].copy(),X_train[test_index].copy(),y_train[train_index].copy(),y_train[test_index].copy()\n",
        "      # learner = SVC(gamma='auto',kernel=ker,C=C_arr)\n",
        "      print(sum(train_y),'Y_label')\n",
        "      \n",
        "      learner.fit(train_x,train_y)\n",
        "      predictions = learner.predict(test_x)\n",
        "      \n",
        "      print('try')\n",
        "      data=train_all.copy()\n",
        "      print(train_index.shape,'before')\n",
        "      marix=new_metrix(data,predictions,unprivileged_groups, privileged_groups,test_index)\n",
        "      print(train_index.shape,'after')\n",
        "      print('X')\n",
        "      # print(marix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SljICdHDrKjI",
        "outputId": "d2ce6fba-6790-4225-8bfb-c08cbeeee71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all\n",
            "6599.0 Y_label\n",
            "try\n",
            "(27351,) before\n",
            "(27351,) after\n",
            "X\n",
            "all\n",
            "6571.0 Y_label\n",
            "try\n",
            "(27351,) before\n",
            "(27351,) after\n",
            "X\n",
            "all\n",
            "6606.0 Y_label\n",
            "try\n",
            "(27351,) before\n",
            "(27351,) after\n",
            "X\n",
            "all\n",
            "6606.0 Y_label\n",
            "try\n",
            "(27351,) before\n",
            "(27351,) after\n",
            "X\n",
            "all\n",
            "6662.0 Y_label\n",
            "try\n",
            "(27352,) before\n",
            "(27352,) after\n",
            "X\n",
            "all\n",
            "6565.0 Y_label\n",
            "try\n",
            "(27351,) before\n",
            "(27351,) after\n",
            "X\n",
            "all\n",
            "6623.0 Y_label\n",
            "try\n",
            "(27351,) before\n",
            "(27351,) after\n",
            "X\n",
            "all\n",
            "6591.0 Y_label\n",
            "try\n",
            "(27351,) before\n",
            "(27351,) after\n",
            "X\n",
            "all\n",
            "6647.0 Y_label\n",
            "try\n",
            "(27351,) before\n",
            "(27351,) after\n",
            "X\n",
            "all\n",
            "6618.0 Y_label\n",
            "try\n",
            "(27352,) before\n",
            "(27352,) after\n",
            "X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_metrix_classifer(alpha_array,solver_array,X_train,y_train):\n",
        "  for C_arr in alpha_array:\n",
        "\n",
        "    for slov in solver_array:\n",
        "      for train_index,test_index in kf.split(X_train):\n",
        "        train_x,test_x,train_y,test_y=X_train[train_index],X_train[test_index],y_train[train_index],y_train[test_index]\n",
        "        learner = MLPClassifier(alpha=C_arr, solver=slov)  \n",
        "      # print(train_y[200:300],'1')\n",
        "      # print(train_x[-1])\n",
        "      \n",
        "        learner.fit(train_x,train_y)\n",
        "        predictions = learner.predict(test_x)\n",
        "        marix=new_metrix(data,predictions,unprivileged_groups, privileged_groups)\n"
      ],
      "metadata": {
        "id": "qcGvF8LIzYgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.metrics import ClassificationMetric\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "score_mean=[]\n",
        "stat_par_diff=[]\n",
        "eq_opp_diff=[]\n",
        "avg_odds_diff=[]\n",
        "alpha_array=[1.0, 100000., 0.001, 0.000001]\n",
        "solver_array=['lbfgs', 'sgd', 'adam']\n",
        "metric_arrs = {}\n",
        "for C_arr in alpha_array:\n",
        "  for slov in solver_array:\n",
        "    \n",
        "\n",
        "    for train_index,test_index in kf.split(X_train):\n",
        "      \n",
        "      train_x,test_x,train_y,test_y=X_train[train_index],X_train[test_index],y_train[train_index],y_train[test_index]\n",
        "      learner = MLPClassifier(alpha=C_arr, solver=slov)  \n",
        "      print(train_y[200:300],'1')\n",
        "      print(train_x[-1])\n",
        "      \n",
        "      learner.fit(train_x,train_y)\n",
        "      predictions = learner.predict(test_x)\n",
        "\n",
        "  # print(predictions.shape)\n",
        "  \n",
        "      train_pred=train.copy()\n",
        "      predictions.resize((len(predictions),1))\n",
        "      train_array=train_pred.labels\n",
        "      train_array[test_index]=predictions\n",
        "\n",
        "      metric = ClassificationMetric(train, train_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "      metric_arrs = {}\n",
        "      metric_arrs['stat_par_diff']=(metric.statistical_parity_difference())\n",
        "      stat_par_diff.append(metric.statistical_parity_difference())\n",
        "      print(stat_par_diff)\n",
        "      # metric_arrs['eq_opp_diff']=(metric.equal_opportunity_difference())\n",
        "      # eq_opp_diff.append(metric.equal_opportunity_difference())\n",
        "      # print(eq_opp_diff)\n",
        "      metric_arrs['avg_odds_diff']=(metric.average_odds_difference())\n",
        "      avg_odds_diff.append(metric.average_odds_difference())\n",
        "    # metric_arrs['mean_stat_par_diff'].append(mean(stat_par_diff))\n",
        "    # print(mean(stat_par_diff))\n",
        "    # metric_arrs['eq_opp_diff'].append(mean(eq_opp_diff))\n",
        "    # metric_arrs['avg_odds_diff'].append(mean(avg_odds_diff))\n",
        "    # metric_arrs['C_slover'].append(C_arr+'_'+slov)\n",
        "\n",
        "df=pd.DataFrame(metric_arrs)\n",
        "print(metric_arrs)\n",
        "\n",
        "  # print(metric_arrs)\n",
        "  # print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ijc_zekbdmRV",
        "outputId": "e1d46bbb-3420-42aa-f064-826e86dc7180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 0. 1. 0. 1.] 1\n",
            "[ 0.41417173 -1.42511042 -0.2314253  -0.57157476 -0.60216288 -0.52874978\n",
            " -0.39611848  3.87764314 -0.14404855 -0.16988074 -0.19633643 -0.11418154\n",
            " -0.69030989 -0.5361253  -0.20976817  5.4488811  -0.232755   -0.57711385]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e1df228a2edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m# print(predictions.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mtrain_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mtrain_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kvxaBDW_dmTn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}